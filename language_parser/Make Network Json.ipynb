{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Duplicate key in file '/Users/seungheondoh/.matplotlib/matplotlibrc' line #2.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('result.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>abstract</th>\n",
       "      <th>author</th>\n",
       "      <th>papername</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Searchlights, Artificial Light, Surveillance,...</td>\n",
       "      <td>Searchlights have been used historically for a...</td>\n",
       "      <td>Claudia Arozqueta</td>\n",
       "      <td>In the Spotlight: Searchlights, Art, Surveilla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Invisible animals, non-human animals, halluci...</td>\n",
       "      <td>My research-creation on invisible animals expl...</td>\n",
       "      <td>Donna Szoke</td>\n",
       "      <td>Invisible Animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Self-representation, quantified self, mobile ...</td>\n",
       "      <td>This paper presents BeHAVE, a web-based audiov...</td>\n",
       "      <td>Sihwa Park</td>\n",
       "      <td>Multimodal Data Portrait for Representing Mobi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Ecological surveillance, Biosensing technolog...</td>\n",
       "      <td>This paper explores merging technology and bio...</td>\n",
       "      <td>Zane Cerpina</td>\n",
       "      <td>Plant Based Bio-Drone for Environmental Monito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Keywords: Bio-art, Schrödinger’s hypothesis o...</td>\n",
       "      <td>This paper introduces Korean bio-artist’s work...</td>\n",
       "      <td>Jongcheon Shin, Siwon Lee, Suk Chon, Keyan Jia...</td>\n",
       "      <td>Seeing Life: The Impalpable Entanglement of an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             keyword  \\\n",
       "0  [Searchlights, Artificial Light, Surveillance,...   \n",
       "1  [Invisible animals, non-human animals, halluci...   \n",
       "2  [Self-representation, quantified self, mobile ...   \n",
       "3  [Ecological surveillance, Biosensing technolog...   \n",
       "4  [Keywords: Bio-art, Schrödinger’s hypothesis o...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Searchlights have been used historically for a...   \n",
       "1  My research-creation on invisible animals expl...   \n",
       "2  This paper presents BeHAVE, a web-based audiov...   \n",
       "3  This paper explores merging technology and bio...   \n",
       "4  This paper introduces Korean bio-artist’s work...   \n",
       "\n",
       "                                              author  \\\n",
       "0                                  Claudia Arozqueta   \n",
       "1                                        Donna Szoke   \n",
       "2                                         Sihwa Park   \n",
       "3                                       Zane Cerpina   \n",
       "4  Jongcheon Shin, Siwon Lee, Suk Chon, Keyan Jia...   \n",
       "\n",
       "                                           papername  \n",
       "0  In the Spotlight: Searchlights, Art, Surveilla...  \n",
       "1                                  Invisible Animals  \n",
       "2  Multimodal Data Portrait for Representing Mobi...  \n",
       "3  Plant Based Bio-Drone for Environmental Monito...  \n",
       "4  Seeing Life: The Impalpable Entanglement of an...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.T\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(df['keyword']):\n",
    "    temp =[]\n",
    "    for j in i:\n",
    "        j = j.lower()\n",
    "        j.replace(\"keywords: \",\"\")\n",
    "        temp.append(j)\n",
    "    df.iloc[idx]['keyword'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>abstract</th>\n",
       "      <th>author</th>\n",
       "      <th>papername</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[searchlights, artificial light, surveillance,...</td>\n",
       "      <td>Searchlights have been used historically for a...</td>\n",
       "      <td>Claudia Arozqueta</td>\n",
       "      <td>In the Spotlight: Searchlights, Art, Surveilla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[invisible animals, non-human animals, halluci...</td>\n",
       "      <td>My research-creation on invisible animals expl...</td>\n",
       "      <td>Donna Szoke</td>\n",
       "      <td>Invisible Animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[self-representation, quantified self, mobile ...</td>\n",
       "      <td>This paper presents BeHAVE, a web-based audiov...</td>\n",
       "      <td>Sihwa Park</td>\n",
       "      <td>Multimodal Data Portrait for Representing Mobi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ecological surveillance, biosensing technolog...</td>\n",
       "      <td>This paper explores merging technology and bio...</td>\n",
       "      <td>Zane Cerpina</td>\n",
       "      <td>Plant Based Bio-Drone for Environmental Monito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[keywords: bio-art, schrödinger’s hypothesis o...</td>\n",
       "      <td>This paper introduces Korean bio-artist’s work...</td>\n",
       "      <td>Jongcheon Shin, Siwon Lee, Suk Chon, Keyan Jia...</td>\n",
       "      <td>Seeing Life: The Impalpable Entanglement of an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             keyword  \\\n",
       "0  [searchlights, artificial light, surveillance,...   \n",
       "1  [invisible animals, non-human animals, halluci...   \n",
       "2  [self-representation, quantified self, mobile ...   \n",
       "3  [ecological surveillance, biosensing technolog...   \n",
       "4  [keywords: bio-art, schrödinger’s hypothesis o...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Searchlights have been used historically for a...   \n",
       "1  My research-creation on invisible animals expl...   \n",
       "2  This paper presents BeHAVE, a web-based audiov...   \n",
       "3  This paper explores merging technology and bio...   \n",
       "4  This paper introduces Korean bio-artist’s work...   \n",
       "\n",
       "                                              author  \\\n",
       "0                                  Claudia Arozqueta   \n",
       "1                                        Donna Szoke   \n",
       "2                                         Sihwa Park   \n",
       "3                                       Zane Cerpina   \n",
       "4  Jongcheon Shin, Siwon Lee, Suk Chon, Keyan Jia...   \n",
       "\n",
       "                                           papername  \n",
       "0  In the Spotlight: Searchlights, Art, Surveilla...  \n",
       "1                                  Invisible Animals  \n",
       "2  Multimodal Data Portrait for Representing Mobi...  \n",
       "3  Plant Based Bio-Drone for Environmental Monito...  \n",
       "4  Seeing Life: The Impalpable Entanglement of an...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def docs_preprocessor(docs):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    docs = docs.lower()  # Convert to lowercase.\n",
    "    docs = tokenizer.tokenize(docs)  # Split into words.\n",
    "    docs = [w for w in docs if not w in stopwords.words('english')]\n",
    "    # Remove numbers, but not words that contain numbers.\n",
    "    docs = [token for token in docs if not token.isdigit()]\n",
    "    # Remove words that are only one character.\n",
    "    docs = [token for token in docs if len(token) > 1]\n",
    "    # Lemmatize all words in documents.\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    docs = [lemmatizer.lemmatize(token) for token in docs]\n",
    "  \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(df['abstract']):\n",
    "    abstract = docs_preprocessor(i)\n",
    "    df.iloc[idx]['abstract'] = abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>abstract</th>\n",
       "      <th>author</th>\n",
       "      <th>papername</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[searchlights, artificial light, surveillance,...</td>\n",
       "      <td>[searchlight, used, historically, artistic, mi...</td>\n",
       "      <td>Claudia Arozqueta</td>\n",
       "      <td>In the Spotlight: Searchlights, Art, Surveilla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[invisible animals, non-human animals, halluci...</td>\n",
       "      <td>[research, creation, invisible, animal, explor...</td>\n",
       "      <td>Donna Szoke</td>\n",
       "      <td>Invisible Animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[self-representation, quantified self, mobile ...</td>\n",
       "      <td>[paper, present, behave, web, based, audiovisu...</td>\n",
       "      <td>Sihwa Park</td>\n",
       "      <td>Multimodal Data Portrait for Representing Mobi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ecological surveillance, biosensing technolog...</td>\n",
       "      <td>[paper, explores, merging, technology, biology...</td>\n",
       "      <td>Zane Cerpina</td>\n",
       "      <td>Plant Based Bio-Drone for Environmental Monito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[keywords: bio-art, schrödinger’s hypothesis o...</td>\n",
       "      <td>[paper, introduces, korean, bio, artist, work,...</td>\n",
       "      <td>Jongcheon Shin, Siwon Lee, Suk Chon, Keyan Jia...</td>\n",
       "      <td>Seeing Life: The Impalpable Entanglement of an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             keyword  \\\n",
       "0  [searchlights, artificial light, surveillance,...   \n",
       "1  [invisible animals, non-human animals, halluci...   \n",
       "2  [self-representation, quantified self, mobile ...   \n",
       "3  [ecological surveillance, biosensing technolog...   \n",
       "4  [keywords: bio-art, schrödinger’s hypothesis o...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  [searchlight, used, historically, artistic, mi...   \n",
       "1  [research, creation, invisible, animal, explor...   \n",
       "2  [paper, present, behave, web, based, audiovisu...   \n",
       "3  [paper, explores, merging, technology, biology...   \n",
       "4  [paper, introduces, korean, bio, artist, work,...   \n",
       "\n",
       "                                              author  \\\n",
       "0                                  Claudia Arozqueta   \n",
       "1                                        Donna Szoke   \n",
       "2                                         Sihwa Park   \n",
       "3                                       Zane Cerpina   \n",
       "4  Jongcheon Shin, Siwon Lee, Suk Chon, Keyan Jia...   \n",
       "\n",
       "                                           papername  \n",
       "0  In the Spotlight: Searchlights, Art, Surveilla...  \n",
       "1                                  Invisible Animals  \n",
       "2  Multimodal Data Portrait for Representing Mobi...  \n",
       "3  Plant Based Bio-Drone for Environmental Monito...  \n",
       "4  Seeing Life: The Impalpable Entanglement of an...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the dependencies\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipdata = zip(df['author'],df['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=_d, tags=[str(i)]) for i, _d in zipdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['research', 'creation', 'invisible', 'animal', 'explores', 'invisible', 'visual', 'realm', 'order', 'explore', 'immanence', 'power', 'non', 'visual', 'knowledge', 'utilizing', 'digital', 'technology', 'create', 'medium', 'artwork', 'think', 'transformational', 'object', 'object', 'shift', 'u', 'new', 'way', 'perceiving', 'leap', 'perception', 'medium', 'art', 'experience', 'change', 'understanding', 'world', 'challenging', 'notion', 'utility', 'animal', 'function', 'technology', 'work', 'offer', 'ethic', 'care', 'liberation', 'instrumental', 'rationalism'], tags=['Donna Szoke'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import gensim\n",
    "from gensim.models import doc2vec\n",
    "from collections import namedtuple\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Doc2Vec(vector_size=50, window=10, min_count=1, workers=8, alpha=0.025, min_alpha=0.015, \n",
    "                              epochs=500)\n",
    "\n",
    "#sample=1e-4, negative=5,\n",
    "\n",
    "#shuffling is better (ot needed at each trianing epoch\n",
    "shuffle(tagged_data)\n",
    "#Build vocabulary from a sequence of sentences \n",
    "model.build_vocab(tagged_data)\n",
    "#Update the model’s neural weights from a sequence of sentences\n",
    "model.train(tagged_data, epochs=model.epochs, total_examples=model.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Honghao Deng, Jiabao Li, Xuesong Zhang & Panagiotis Michalatos',\n",
       "  0.6657871007919312),\n",
       " ('Janna Ahrndt', 0.6189479827880859),\n",
       " ('Irene Eunyoung Lee', 0.6155557632446289),\n",
       " ('Sara Bonaventura', 0.6088194251060486),\n",
       " ('Kyungho Lee', 0.6029232740402222),\n",
       " ('Tobias Klein & Harald Kraemer', 0.5790026187896729),\n",
       " ('Young Ho Kim, Yang Kyu Lim & Jin Wan Park', 0.5686557292938232),\n",
       " ('Scott Rettberg', 0.5645945072174072),\n",
       " ('Lingdong Huang, Zheng Jiang, Syuan-Cheng Sun, Tong Bai, Eunsu Kang & Barnabas Poczos',\n",
       "  0.5350003838539124),\n",
       " ('Cynthia Patricia Villagomez Oviedo', 0.5324043035507202),\n",
       " ('Claudia Costa Pederson', 0.525152862071991),\n",
       " ('Paula Andrea Escandón, Andrés Felipe Roldán & Fernando Luna',\n",
       "  0.5104857683181763),\n",
       " ('Ian Willcock', 0.5005378127098083),\n",
       " ('Ellen Pearlman', 0.49880343675613403),\n",
       " ('Sihwa Park', 0.49823468923568726),\n",
       " ('Intae Hwang & Alenda Y. Chang', 0.4978932738304138),\n",
       " ('Marios Samdanis, Chrystalla Kapetaniou, Yi Kyung Kim & Soo Hee Lee',\n",
       "  0.49762022495269775),\n",
       " ('John Power', 0.49005645513534546),\n",
       " ('Vít Ružicka, Eunsu Kang, David Gordon, Ankita Patel, Jacqui Fashimpaur & Manzil Zaheer',\n",
       "  0.48855340480804443),\n",
       " ('Andrew Richardson', 0.48497164249420166),\n",
       " ('Maria Lantin, Alexandra Hass, Simon Lysander Overstall',\n",
       "  0.48423057794570923),\n",
       " ('Masayuki Akamatsu, Yasuko Imura, Tomoki Kobayashi, Iku Harada & Shigeru Matsui',\n",
       "  0.48285815119743347),\n",
       " ('Haoyi Zhang', 0.4811464846134186),\n",
       " ('Andrew R. Brown, John Ferguson & Andy Bennett', 0.48096752166748047),\n",
       " ('Sojung Bahng, Toby Gifford & Jon McCormack', 0.47698575258255005),\n",
       " ('Anatol Bologan, Dr. Jinsil Seo, Joseph Orr & Vidya Sridhar',\n",
       "  0.47659677267074585),\n",
       " ('Kiran Bhumber & Nancy Lee', 0.47066694498062134),\n",
       " ('Pablo Gobira & Emanuelle de Oliveira Silva', 0.46853742003440857),\n",
       " ('Aleksandra Dulic & Miles Thorogood', 0.46214115619659424),\n",
       " ('Reynaldo Thompson & Tirtha Prasad Mukhopadhyay', 0.46064630150794983),\n",
       " ('Jens Herder, Shinpei Takeda, Kai Vermeegen, Till Davin, Dominique Berners, Bektur Ryskeldiev, Christian Zimmer, Ivana Druzetic & Christian Geiger',\n",
       "  0.45710548758506775),\n",
       " ('Nima Navab & Desiree Foerster', 0.45682722330093384),\n",
       " ('Ardavan Bidgoli, Eunsu Kang & Daniel Cardoso Llach', 0.4540322422981262),\n",
       " ('Carly Whitaker', 0.4495576322078705),\n",
       " ('Tomas Laurenzo', 0.44683465361595154),\n",
       " ('David Han', 0.4422377347946167),\n",
       " ('Clarissa Ribeiro', 0.4415215253829956),\n",
       " ('Benjamin Horn', 0.44110530614852905),\n",
       " ('Larissa Hjorth', 0.43257346749305725),\n",
       " ('Nadja Lipsyc', 0.42852693796157837),\n",
       " ('Jongcheon Shin, Siwon Lee, Suk Chon, Keyan Jiang & Joonsung Yoon',\n",
       "  0.42684346437454224),\n",
       " ('Georgia Smithson', 0.423200786113739),\n",
       " ('Helena Ferreira', 0.4224950671195984),\n",
       " ('Anna Madeleine Raupach', 0.41654258966445923),\n",
       " ('Jason Kennedy', 0.41085442900657654),\n",
       " ('Kazuhiro Jo, Ryota Kuwakubo, Akira Segawa, Takuro Oshima, Yusuke Gushiken, Asami Takami & johnsmith',\n",
       "  0.4055106043815613),\n",
       " ('Jing Han', 0.4027823209762573),\n",
       " ('Ha Na Lee & James Hughes', 0.4024691879749298),\n",
       " ('Sung-A Jang & Benjamin L’Huillier', 0.4006126821041107),\n",
       " ('Brendan Harwood', 0.40047192573547363),\n",
       " ('Paul Sermon', 0.40030574798583984),\n",
       " ('Hyun Jean Lee, Wonjean Lee, Hyungsin Kim & Jeong Han Kim',\n",
       "  0.3963829576969147),\n",
       " ('Aurélie Besson', 0.3956388235092163),\n",
       " ('Stahl Stenslie', 0.39459818601608276),\n",
       " ('Yan Breuleux & Rémi Lapierre', 0.39303144812583923),\n",
       " ('Mariana Pérez-Bobadilla', 0.39095354080200195),\n",
       " ('James Shea', 0.39021265506744385),\n",
       " ('Tadeus Mucelli', 0.3847014307975769),\n",
       " ('Yolande Harris', 0.3830175995826721),\n",
       " ('Anne Nigten & Annemarie Piscaer', 0.3790014982223511),\n",
       " ('Alejandro Rodriguez & Tomas Laurenzo', 0.3772270679473877),\n",
       " ('Sey Min & Jihye Lee', 0.3753274083137512),\n",
       " ('Taekyeom Lee', 0.37418332695961),\n",
       " ('Yanai Toister', 0.37347525358200073),\n",
       " ('Sadia Sadia', 0.373382568359375),\n",
       " ('Jiayue Cecilia Wu & Donghao Ren', 0.3715265393257141),\n",
       " ('Sieun Park, Suk Chon, Tiffany Lee & Jusub Kim', 0.3703853487968445),\n",
       " ('Michel van Dartel & Alwin de Rooij', 0.3691282868385315),\n",
       " ('Honghao Deng, Jiabao Li, Allen Sayegh', 0.36899039149284363),\n",
       " ('Jin Woo Lee, Yikyung Kim & Soo Hee Lee', 0.36581850051879883),\n",
       " ('Sabina Hyoju Ahn', 0.36548593640327454),\n",
       " ('Joel Ong', 0.3641746938228607),\n",
       " ('Lindsay D. Grace', 0.3577117919921875),\n",
       " ('Benjamin Seide, Ross Williams & Elke Reinhuber', 0.35397589206695557),\n",
       " ('Donna Szoke', 0.35206905007362366),\n",
       " ('Songwei Ge, Austin Dill, Eunsu Kang, Chun-Liang Li, Lingyao Zhang Manzil Zaheer & Barnabas Poczos',\n",
       "  0.3502199351787567),\n",
       " ('Semi Ryu, Danielle Noreika, Malisa Dang & Egidio Del Fabbro',\n",
       "  0.34981727600097656),\n",
       " ('Jeehyun Yang, Jaesik Jeong & Jacky Baltes', 0.3435693383216858),\n",
       " ('Jiabao Li, Honghao Deng & Panagiotis Michalatos', 0.34348630905151367),\n",
       " ('Anastasia Tyurina', 0.3344639539718628),\n",
       " ('João Martinho Moura, Né Barros & Paulo Ferreira-Lopes', 0.3343510627746582),\n",
       " ('Gyung Jin Shin', 0.33012428879737854),\n",
       " ('Yingdao Jiang, Li Yang, Yingquan Wang & Joonsung Yoon', 0.3266366720199585),\n",
       " ('Kyle Chung', 0.31789690256118774),\n",
       " ('Haru (Hyunkyung) Ji & Graham Wakefield', 0.3175774812698364),\n",
       " ('Eun Sun Chu, Jacqueline Gonzalez, Jinsil Hwaryoung Seo & Caleb Kicklighter',\n",
       "  0.3134382367134094),\n",
       " ('Mengyu Chen, Jing Yan & Yin Yu', 0.3024759292602539),\n",
       " ('Minso Kim', 0.29173731803894043),\n",
       " ('Raivo Kelomees', 0.28728461265563965),\n",
       " ('Steven Devleminck, Boris Debackere & Toon Van Waterschoot',\n",
       "  0.2828749418258667),\n",
       " ('Meredith Drum', 0.2767382860183716),\n",
       " ('Jooyoung Oh & Byungjoo Lee', 0.2748379707336426),\n",
       " ('Francisco Gerardo Toledo Ramírez', 0.2731840908527374),\n",
       " ('Jinsil Hwaryoung Seo, Eman Al-Zubeidi, Courtney Michalsky, Stephanie Sykora & Lauren Toler',\n",
       "  0.27007538080215454),\n",
       " ('Zane Cerpina', 0.26767128705978394),\n",
       " ('Varvara Guljajeva', 0.2541978657245636),\n",
       " ('David Behar', 0.22843769192695618),\n",
       " ('Marinos Koutsomichalis', 0.21641460061073303),\n",
       " ('Bert Vandenberghe, Kathrin Gerling, Luc Geurts, Vero Vanden Abeele & Steven Devleminck',\n",
       "  0.19955739378929138),\n",
       " ('Chanjun Mu', 0.19353215396404266)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.most_similar('Claudia Arozqueta', topn=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = model.docvecs.index2entity\n",
    "len(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "author2author =[]\n",
    "for i in col:\n",
    "    for n,v in model.docvecs.most_similar(i, topn=101):\n",
    "        if v > 0.5:\n",
    "            documents = {}\n",
    "            documents['source'] = i\n",
    "            documents['target'] = n\n",
    "            author2author.append(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': 'David Han', 'target': 'Nadja Lipsyc'},\n",
       " {'source': 'David Han', 'target': 'Kiran Bhumber & Nancy Lee'},\n",
       " {'source': 'David Han',\n",
       "  'target': 'Eun Sun Chu, Jacqueline Gonzalez, Jinsil Hwaryoung Seo & Caleb Kicklighter'},\n",
       " {'source': 'David Han', 'target': 'Irene Eunyoung Lee'},\n",
       " {'source': 'David Han',\n",
       "  'target': 'Sieun Park, Suk Chon, Tiffany Lee & Jusub Kim'}]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author2author[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "author2keyword = []\n",
    "for i in range(len(df)):\n",
    "    for j in df.iloc[i]['keyword']:\n",
    "        documents = {}\n",
    "        documents['source'] = df.iloc[i]['author']\n",
    "        documents['target'] = j.replace('keywords: ','')\n",
    "        author2keyword.append(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': 'Claudia Arozqueta', 'target': 'searchlights'},\n",
       " {'source': 'Claudia Arozqueta', 'target': 'artificial light'},\n",
       " {'source': 'Claudia Arozqueta', 'target': 'surveillance'},\n",
       " {'source': 'Claudia Arozqueta', 'target': 'installation art'},\n",
       " {'source': 'Claudia Arozqueta', 'target': 'memorial art'}]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author2keyword[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = []\n",
    "for i in range(len(df)):\n",
    "    documents = {}\n",
    "    documents['id'] = df.iloc[i]['author']\n",
    "    documents['label'] = 'author'\n",
    "    node.append(documents)\n",
    "    for j in df.iloc[i]['keyword']:\n",
    "        keydoc = {}\n",
    "        keydoc['id'] = j\n",
    "        keydoc['label'] = 'keyword'\n",
    "        node.append(keydoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'Claudia Arozqueta', 'label': 'author'},\n",
       " {'id': 'searchlights', 'label': 'keyword'},\n",
       " {'id': 'artificial light', 'label': 'keyword'},\n",
       " {'id': 'surveillance', 'label': 'keyword'},\n",
       " {'id': 'installation art', 'label': 'keyword'}]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('author2author.json', 'w') as f:\n",
    "    json.dump(author2author , f)\n",
    "with open('author2keyword.json', 'w') as f:\n",
    "    json.dump(author2keyword , f)\n",
    "with open('node.json', 'w') as f:\n",
    "    json.dump(node , f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
