{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('result.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>abstract</th>\n",
       "      <th>author</th>\n",
       "      <th>papername</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Searchlights, Artificial Light, Surveillance,...</td>\n",
       "      <td>Searchlights have been used historically for a...</td>\n",
       "      <td>Claudia Arozqueta</td>\n",
       "      <td>In the Spotlight: Searchlights, Art, Surveilla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Invisible animals, non-human animals, halluci...</td>\n",
       "      <td>My research-creation on invisible animals expl...</td>\n",
       "      <td>Donna Szoke</td>\n",
       "      <td>Invisible Animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Self-representation, quantified self, mobile ...</td>\n",
       "      <td>This paper presents BeHAVE, a web-based audiov...</td>\n",
       "      <td>Sihwa Park</td>\n",
       "      <td>Multimodal Data Portrait for Representing Mobi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Ecological surveillance, Biosensing technolog...</td>\n",
       "      <td>This paper explores merging technology and bio...</td>\n",
       "      <td>Zane Cerpina</td>\n",
       "      <td>Plant Based Bio-Drone for Environmental Monito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Keywords: Bio-art, Schrödinger’s hypothesis o...</td>\n",
       "      <td>This paper introduces Korean bio-artist’s work...</td>\n",
       "      <td>Jongcheon Shin, Siwon Lee, Suk Chon, Keyan Jia...</td>\n",
       "      <td>Seeing Life: The Impalpable Entanglement of an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             keyword  \\\n",
       "0  [Searchlights, Artificial Light, Surveillance,...   \n",
       "1  [Invisible animals, non-human animals, halluci...   \n",
       "2  [Self-representation, quantified self, mobile ...   \n",
       "3  [Ecological surveillance, Biosensing technolog...   \n",
       "4  [Keywords: Bio-art, Schrödinger’s hypothesis o...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Searchlights have been used historically for a...   \n",
       "1  My research-creation on invisible animals expl...   \n",
       "2  This paper presents BeHAVE, a web-based audiov...   \n",
       "3  This paper explores merging technology and bio...   \n",
       "4  This paper introduces Korean bio-artist’s work...   \n",
       "\n",
       "                                              author  \\\n",
       "0                                  Claudia Arozqueta   \n",
       "1                                        Donna Szoke   \n",
       "2                                         Sihwa Park   \n",
       "3                                       Zane Cerpina   \n",
       "4  Jongcheon Shin, Siwon Lee, Suk Chon, Keyan Jia...   \n",
       "\n",
       "                                           papername  \n",
       "0  In the Spotlight: Searchlights, Art, Surveilla...  \n",
       "1                                  Invisible Animals  \n",
       "2  Multimodal Data Portrait for Representing Mobi...  \n",
       "3  Plant Based Bio-Drone for Environmental Monito...  \n",
       "4  Seeing Life: The Impalpable Entanglement of an...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.T\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(df['keyword']):\n",
    "    temp =[]\n",
    "    for j in i:\n",
    "        j = j.lower()\n",
    "        j.replace(\"keywords: \",\"\")\n",
    "        temp.append(j)\n",
    "    df.iloc[idx]['keyword'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>abstract</th>\n",
       "      <th>author</th>\n",
       "      <th>papername</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[searchlights, artificial light, surveillance,...</td>\n",
       "      <td>Searchlights have been used historically for a...</td>\n",
       "      <td>Claudia Arozqueta</td>\n",
       "      <td>In the Spotlight: Searchlights, Art, Surveilla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[invisible animals, non-human animals, halluci...</td>\n",
       "      <td>My research-creation on invisible animals expl...</td>\n",
       "      <td>Donna Szoke</td>\n",
       "      <td>Invisible Animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[self-representation, quantified self, mobile ...</td>\n",
       "      <td>This paper presents BeHAVE, a web-based audiov...</td>\n",
       "      <td>Sihwa Park</td>\n",
       "      <td>Multimodal Data Portrait for Representing Mobi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ecological surveillance, biosensing technolog...</td>\n",
       "      <td>This paper explores merging technology and bio...</td>\n",
       "      <td>Zane Cerpina</td>\n",
       "      <td>Plant Based Bio-Drone for Environmental Monito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[keywords: bio-art, schrödinger’s hypothesis o...</td>\n",
       "      <td>This paper introduces Korean bio-artist’s work...</td>\n",
       "      <td>Jongcheon Shin, Siwon Lee, Suk Chon, Keyan Jia...</td>\n",
       "      <td>Seeing Life: The Impalpable Entanglement of an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             keyword  \\\n",
       "0  [searchlights, artificial light, surveillance,...   \n",
       "1  [invisible animals, non-human animals, halluci...   \n",
       "2  [self-representation, quantified self, mobile ...   \n",
       "3  [ecological surveillance, biosensing technolog...   \n",
       "4  [keywords: bio-art, schrödinger’s hypothesis o...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Searchlights have been used historically for a...   \n",
       "1  My research-creation on invisible animals expl...   \n",
       "2  This paper presents BeHAVE, a web-based audiov...   \n",
       "3  This paper explores merging technology and bio...   \n",
       "4  This paper introduces Korean bio-artist’s work...   \n",
       "\n",
       "                                              author  \\\n",
       "0                                  Claudia Arozqueta   \n",
       "1                                        Donna Szoke   \n",
       "2                                         Sihwa Park   \n",
       "3                                       Zane Cerpina   \n",
       "4  Jongcheon Shin, Siwon Lee, Suk Chon, Keyan Jia...   \n",
       "\n",
       "                                           papername  \n",
       "0  In the Spotlight: Searchlights, Art, Surveilla...  \n",
       "1                                  Invisible Animals  \n",
       "2  Multimodal Data Portrait for Representing Mobi...  \n",
       "3  Plant Based Bio-Drone for Environmental Monito...  \n",
       "4  Seeing Life: The Impalpable Entanglement of an...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def docs_preprocessor(docs):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    docs = docs.lower()  # Convert to lowercase.\n",
    "    docs = tokenizer.tokenize(docs)  # Split into words.\n",
    "    docs = [w for w in docs if not w in stopwords.words('english')]\n",
    "    # Remove numbers, but not words that contain numbers.\n",
    "    docs = [token for token in docs if not token.isdigit()]\n",
    "    # Remove words that are only one character.\n",
    "    docs = [token for token in docs if len(token) > 1]\n",
    "    # Lemmatize all words in documents.\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    docs = [lemmatizer.lemmatize(token) for token in docs]\n",
    "  \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(df['abstract']):\n",
    "    abstract = docs_preprocessor(i)\n",
    "    df.iloc[idx]['abstract'] = abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>abstract</th>\n",
       "      <th>author</th>\n",
       "      <th>papername</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[searchlights, artificial light, surveillance,...</td>\n",
       "      <td>[searchlight, used, historically, artistic, mi...</td>\n",
       "      <td>Claudia Arozqueta</td>\n",
       "      <td>In the Spotlight: Searchlights, Art, Surveilla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[invisible animals, non-human animals, halluci...</td>\n",
       "      <td>[research, creation, invisible, animal, explor...</td>\n",
       "      <td>Donna Szoke</td>\n",
       "      <td>Invisible Animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[self-representation, quantified self, mobile ...</td>\n",
       "      <td>[paper, present, behave, web, based, audiovisu...</td>\n",
       "      <td>Sihwa Park</td>\n",
       "      <td>Multimodal Data Portrait for Representing Mobi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ecological surveillance, biosensing technolog...</td>\n",
       "      <td>[paper, explores, merging, technology, biology...</td>\n",
       "      <td>Zane Cerpina</td>\n",
       "      <td>Plant Based Bio-Drone for Environmental Monito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[keywords: bio-art, schrödinger’s hypothesis o...</td>\n",
       "      <td>[paper, introduces, korean, bio, artist, work,...</td>\n",
       "      <td>Jongcheon Shin, Siwon Lee, Suk Chon, Keyan Jia...</td>\n",
       "      <td>Seeing Life: The Impalpable Entanglement of an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             keyword  \\\n",
       "0  [searchlights, artificial light, surveillance,...   \n",
       "1  [invisible animals, non-human animals, halluci...   \n",
       "2  [self-representation, quantified self, mobile ...   \n",
       "3  [ecological surveillance, biosensing technolog...   \n",
       "4  [keywords: bio-art, schrödinger’s hypothesis o...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  [searchlight, used, historically, artistic, mi...   \n",
       "1  [research, creation, invisible, animal, explor...   \n",
       "2  [paper, present, behave, web, based, audiovisu...   \n",
       "3  [paper, explores, merging, technology, biology...   \n",
       "4  [paper, introduces, korean, bio, artist, work,...   \n",
       "\n",
       "                                              author  \\\n",
       "0                                  Claudia Arozqueta   \n",
       "1                                        Donna Szoke   \n",
       "2                                         Sihwa Park   \n",
       "3                                       Zane Cerpina   \n",
       "4  Jongcheon Shin, Siwon Lee, Suk Chon, Keyan Jia...   \n",
       "\n",
       "                                           papername  \n",
       "0  In the Spotlight: Searchlights, Art, Surveilla...  \n",
       "1                                  Invisible Animals  \n",
       "2  Multimodal Data Portrait for Representing Mobi...  \n",
       "3  Plant Based Bio-Drone for Environmental Monito...  \n",
       "4  Seeing Life: The Impalpable Entanglement of an...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the dependencies\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipdata = zip(df['author'],df['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=_d, tags=[str(i)]) for i, _d in zipdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['research', 'creation', 'invisible', 'animal', 'explores', 'invisible', 'visual', 'realm', 'order', 'explore', 'immanence', 'power', 'non', 'visual', 'knowledge', 'utilizing', 'digital', 'technology', 'create', 'medium', 'artwork', 'think', 'transformational', 'object', 'object', 'shift', 'u', 'new', 'way', 'perceiving', 'leap', 'perception', 'medium', 'art', 'experience', 'change', 'understanding', 'world', 'challenging', 'notion', 'utility', 'animal', 'function', 'technology', 'work', 'offer', 'ethic', 'care', 'liberation', 'instrumental', 'rationalism'], tags=['Donna Szoke'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import gensim\n",
    "from gensim.models import doc2vec\n",
    "from collections import namedtuple\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Doc2Vec(vector_size=50, window=10, min_count=1, workers=8, alpha=0.025, min_alpha=0.015, \n",
    "                              epochs=500)\n",
    "\n",
    "#sample=1e-4, negative=5,\n",
    "\n",
    "#shuffling is better (ot needed at each trianing epoch\n",
    "shuffle(tagged_data)\n",
    "#Build vocabulary from a sequence of sentences \n",
    "model.build_vocab(tagged_data)\n",
    "#Update the model’s neural weights from a sequence of sentences\n",
    "model.train(tagged_data, epochs=model.epochs, total_examples=model.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Janna Ahrndt', 0.6277286410331726),\n",
       " ('Honghao Deng, Jiabao Li, Xuesong Zhang & Panagiotis Michalatos',\n",
       "  0.6229113340377808),\n",
       " ('Sara Bonaventura', 0.620789110660553),\n",
       " ('Lingdong Huang, Zheng Jiang, Syuan-Cheng Sun, Tong Bai, Eunsu Kang & Barnabas Poczos',\n",
       "  0.6007415652275085),\n",
       " ('Kyungho Lee', 0.5934253334999084),\n",
       " ('Irene Eunyoung Lee', 0.592743992805481),\n",
       " ('Tobias Klein & Harald Kraemer', 0.5686616897583008),\n",
       " ('Young Ho Kim, Yang Kyu Lim & Jin Wan Park', 0.5631190538406372),\n",
       " ('Scott Rettberg', 0.5541275143623352),\n",
       " ('Claudia Costa Pederson', 0.5289748907089233),\n",
       " ('Intae Hwang & Alenda Y. Chang', 0.5232059955596924),\n",
       " ('Aleksandra Dulic & Miles Thorogood', 0.508289098739624),\n",
       " ('Paula Andrea Escandón, Andrés Felipe Roldán & Fernando Luna',\n",
       "  0.4979220926761627),\n",
       " ('Jason Kennedy', 0.4967525005340576),\n",
       " ('Haoyi Zhang', 0.49611949920654297),\n",
       " ('Masayuki Akamatsu, Yasuko Imura, Tomoki Kobayashi, Iku Harada & Shigeru Matsui',\n",
       "  0.4944039583206177),\n",
       " ('Ian Willcock', 0.49351295828819275),\n",
       " ('Cynthia Patricia Villagomez Oviedo', 0.49292024970054626),\n",
       " ('Maria Lantin, Alexandra Hass, Simon Lysander Overstall',\n",
       "  0.48743486404418945),\n",
       " ('John Power', 0.4833701550960541),\n",
       " ('Andrew Richardson', 0.48263025283813477),\n",
       " ('Sojung Bahng, Toby Gifford & Jon McCormack', 0.4799017310142517),\n",
       " ('Andrew R. Brown, John Ferguson & Andy Bennett', 0.4784962236881256),\n",
       " ('Brendan Harwood', 0.4774553179740906),\n",
       " ('Vít Ružicka, Eunsu Kang, David Gordon, Ankita Patel, Jacqui Fashimpaur & Manzil Zaheer',\n",
       "  0.4712190628051758),\n",
       " ('Larissa Hjorth', 0.46823716163635254),\n",
       " ('Helena Ferreira', 0.46681785583496094),\n",
       " ('Anatol Bologan, Dr. Jinsil Seo, Joseph Orr & Vidya Sridhar',\n",
       "  0.46645355224609375),\n",
       " ('Reynaldo Thompson & Tirtha Prasad Mukhopadhyay', 0.4631959795951843),\n",
       " ('Georgia Smithson', 0.4616295099258423),\n",
       " ('Honghao Deng, Jiabao Li, Allen Sayegh', 0.4605335593223572),\n",
       " ('Ellen Pearlman', 0.45727646350860596),\n",
       " ('Marios Samdanis, Chrystalla Kapetaniou, Yi Kyung Kim & Soo Hee Lee',\n",
       "  0.45067209005355835),\n",
       " ('Jongcheon Shin, Siwon Lee, Suk Chon, Keyan Jiang & Joonsung Yoon',\n",
       "  0.4501696527004242),\n",
       " ('Alejandro Rodriguez & Tomas Laurenzo', 0.44862741231918335),\n",
       " ('Clarissa Ribeiro', 0.44826874136924744),\n",
       " ('Carly Whitaker', 0.44511324167251587),\n",
       " ('Pablo Gobira & Emanuelle de Oliveira Silva', 0.4448224902153015),\n",
       " ('Ha Na Lee & James Hughes', 0.44322919845581055),\n",
       " ('Anna Madeleine Raupach', 0.44272130727767944),\n",
       " ('Benjamin Horn', 0.44116827845573425),\n",
       " ('Ardavan Bidgoli, Eunsu Kang & Daniel Cardoso Llach', 0.4371219873428345),\n",
       " ('Sihwa Park', 0.4287908375263214),\n",
       " ('Sung-A Jang & Benjamin L’Huillier', 0.42343366146087646),\n",
       " ('Michel van Dartel & Alwin de Rooij', 0.41956472396850586),\n",
       " ('Kiran Bhumber & Nancy Lee', 0.41814571619033813),\n",
       " ('James Shea', 0.4176146388053894),\n",
       " ('Jens Herder, Shinpei Takeda, Kai Vermeegen, Till Davin, Dominique Berners, Bektur Ryskeldiev, Christian Zimmer, Ivana Druzetic & Christian Geiger',\n",
       "  0.41332224011421204),\n",
       " ('Gyung Jin Shin', 0.4061861038208008),\n",
       " ('Tomas Laurenzo', 0.40571120381355286),\n",
       " ('Jing Han', 0.40454989671707153),\n",
       " ('Nima Navab & Desiree Foerster', 0.3939495086669922),\n",
       " ('Kazuhiro Jo, Ryota Kuwakubo, Akira Segawa, Takuro Oshima, Yusuke Gushiken, Asami Takami & johnsmith',\n",
       "  0.39244991540908813),\n",
       " ('Nadja Lipsyc', 0.39223670959472656),\n",
       " ('Mariana Pérez-Bobadilla', 0.38981783390045166),\n",
       " ('Songwei Ge, Austin Dill, Eunsu Kang, Chun-Liang Li, Lingyao Zhang Manzil Zaheer & Barnabas Poczos',\n",
       "  0.38782986998558044),\n",
       " ('Jiayue Cecilia Wu & Donghao Ren', 0.38704410195350647),\n",
       " ('Yingdao Jiang, Li Yang, Yingquan Wang & Joonsung Yoon',\n",
       "  0.38513365387916565),\n",
       " ('Semi Ryu, Danielle Noreika, Malisa Dang & Egidio Del Fabbro',\n",
       "  0.3796931505203247),\n",
       " ('Yanai Toister', 0.3793346881866455),\n",
       " ('Tadeus Mucelli', 0.37840765714645386),\n",
       " ('Paul Sermon', 0.37452733516693115),\n",
       " ('Raivo Kelomees', 0.3742128610610962),\n",
       " ('David Han', 0.36907750368118286),\n",
       " ('Anne Nigten & Annemarie Piscaer', 0.36722105741500854),\n",
       " ('Hyun Jean Lee, Wonjean Lee, Hyungsin Kim & Jeong Han Kim',\n",
       "  0.35671553015708923),\n",
       " ('Sey Min & Jihye Lee', 0.35333824157714844),\n",
       " ('Jiabao Li, Honghao Deng & Panagiotis Michalatos', 0.34978193044662476),\n",
       " ('Yan Breuleux & Rémi Lapierre', 0.34951138496398926),\n",
       " ('Aurélie Besson', 0.34854280948638916),\n",
       " ('Joel Ong', 0.3467581570148468),\n",
       " ('Jeehyun Yang, Jaesik Jeong & Jacky Baltes', 0.34602612257003784),\n",
       " ('Taekyeom Lee', 0.33942389488220215),\n",
       " ('Meredith Drum', 0.3382313847541809),\n",
       " ('Jooyoung Oh & Byungjoo Lee', 0.3368789255619049),\n",
       " ('Anastasia Tyurina', 0.3364959955215454),\n",
       " ('Jinsil Hwaryoung Seo, Eman Al-Zubeidi, Courtney Michalsky, Stephanie Sykora & Lauren Toler',\n",
       "  0.32965201139450073),\n",
       " ('Eun Sun Chu, Jacqueline Gonzalez, Jinsil Hwaryoung Seo & Caleb Kicklighter',\n",
       "  0.3295697271823883),\n",
       " ('Sieun Park, Suk Chon, Tiffany Lee & Jusub Kim', 0.32522767782211304),\n",
       " ('Chanjun Mu', 0.3214462101459503),\n",
       " ('Donna Szoke', 0.317058801651001),\n",
       " ('Zane Cerpina', 0.3165140450000763),\n",
       " ('Yolande Harris', 0.31551188230514526),\n",
       " ('Benjamin Seide, Ross Williams & Elke Reinhuber', 0.31106314063072205),\n",
       " ('Varvara Guljajeva', 0.30888479948043823),\n",
       " ('Kyle Chung', 0.3085736334323883),\n",
       " ('Lindsay D. Grace', 0.30807194113731384),\n",
       " ('Jin Woo Lee, Yikyung Kim & Soo Hee Lee', 0.30783459544181824),\n",
       " ('Francisco Gerardo Toledo Ramírez', 0.3042479157447815),\n",
       " ('Bert Vandenberghe, Kathrin Gerling, Luc Geurts, Vero Vanden Abeele & Steven Devleminck',\n",
       "  0.30182400345802307),\n",
       " ('Sabina Hyoju Ahn', 0.30034682154655457),\n",
       " ('Haru (Hyunkyung) Ji & Graham Wakefield', 0.30020153522491455),\n",
       " ('Sadia Sadia', 0.29954326152801514),\n",
       " ('Stahl Stenslie', 0.2950766384601593),\n",
       " ('João Martinho Moura, Né Barros & Paulo Ferreira-Lopes',\n",
       "  0.29037559032440186),\n",
       " ('Mengyu Chen, Jing Yan & Yin Yu', 0.2781275510787964),\n",
       " ('Minso Kim', 0.2707239091396332),\n",
       " ('Steven Devleminck, Boris Debackere & Toon Van Waterschoot',\n",
       "  0.2628400921821594),\n",
       " ('Marinos Koutsomichalis', 0.22753916680812836),\n",
       " ('David Behar', 0.2184741050004959)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.most_similar('Claudia Arozqueta', topn=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = model.docvecs.index2entity\n",
    "len(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "author2author =[]\n",
    "for i in col:\n",
    "    for n,v in model.docvecs.most_similar(i, topn=101):\n",
    "        if v > 0.5:\n",
    "            documents = {}\n",
    "            documents['source'] = i\n",
    "            documents['target'] = n\n",
    "            author2author.append(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': 'Meredith Drum', 'target': 'Irene Eunyoung Lee'},\n",
       " {'source': 'Meredith Drum', 'target': 'Kyungho Lee'},\n",
       " {'source': 'Meredith Drum', 'target': 'Anna Madeleine Raupach'},\n",
       " {'source': 'Meredith Drum', 'target': 'Ian Willcock'},\n",
       " {'source': 'Meredith Drum', 'target': 'Minso Kim'}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author2author[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "author2keyword = []\n",
    "for i in range(len(df)):\n",
    "    for j in df.iloc[i]['keyword']:\n",
    "        documents = {}\n",
    "        documents['source'] = df.iloc[i]['author']\n",
    "        documents['target'] = j.replace('keywords: ','')\n",
    "        author2keyword.append(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': 'Claudia Arozqueta', 'target': 'searchlights'},\n",
       " {'source': 'Claudia Arozqueta', 'target': 'artificial light'},\n",
       " {'source': 'Claudia Arozqueta', 'target': 'surveillance'},\n",
       " {'source': 'Claudia Arozqueta', 'target': 'installation art'},\n",
       " {'source': 'Claudia Arozqueta', 'target': 'memorial art'}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author2keyword[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = []\n",
    "for i in range(len(df)):\n",
    "    documents = {}\n",
    "    documents['id'] = df.iloc[i]['author']\n",
    "    documents['label'] = 'author'\n",
    "    node.append(documents)\n",
    "    for j in df.iloc[i]['keyword']:\n",
    "        keydoc = {}\n",
    "        keydoc['id'] = j\n",
    "        keydoc['label'] = 'keyword'\n",
    "        node.append(keydoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'Claudia Arozqueta', 'label': 'author'},\n",
       " {'id': 'searchlights', 'label': 'keyword'},\n",
       " {'id': 'artificial light', 'label': 'keyword'},\n",
       " {'id': 'surveillance', 'label': 'keyword'},\n",
       " {'id': 'installation art', 'label': 'keyword'}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('author2author.json', 'w') as f:\n",
    "    json.dump(author2author , f, indent='\\t')\n",
    "with open('author2keyword.json', 'w') as f:\n",
    "    json.dump(author2keyword , f, indent='\\t')\n",
    "with open('node.json', 'w') as f:\n",
    "    json.dump(node , f, indent='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
